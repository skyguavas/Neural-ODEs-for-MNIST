{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN7RjHG7cLWRSXH9fJke3m2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyguavas/Neural-ODEs-for-MNIST/blob/main/ML_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38Q0lti0tjHf",
        "outputId": "276fc909-9311-4a57-edb2-9394e48bacce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.10/dist-packages (0.2.4)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.3.0+cu121)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->torchdiffeq) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torchdiffeq) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "!pip install torchdiffeq\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# parser and conditional import of ode\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')\n",
        "parser.add_argument('--tol', type=float, default=1e-3)\n",
        "parser.add_argument('--adjoint', type=eval, default=True, choices=[True, False])\n",
        "parser.add_argument('--downsampling-method', type=str, default='conv', choices=['conv', 'res'])\n",
        "parser.add_argument('--nepochs', type=int, default=160)\n",
        "parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])\n",
        "parser.add_argument('--lr', type=float, default=0.1)\n",
        "parser.add_argument('--batch_size', type=int, default=128)\n",
        "parser.add_argument('--test_batch_size', type=int, default=1000)\n",
        "\n",
        "parser.add_argument('--save', type=str, default='./experiment1')\n",
        "parser.add_argument('--debug', action='store_true')\n",
        "parser.add_argument('--gpu', type=int, default=0)\n",
        "args = parser.parse_args(args=[]) # changed this line to make it colab-runnable\n",
        "\n",
        "if args.adjoint:\n",
        "    from torchdiffeq import odeint_adjoint as odeint\n",
        "else:\n",
        "    from torchdiffeq import odeint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model structure\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "def norm(dim):\n",
        "    return nn.GroupNorm(min(32, dim), dim)"
      ],
      "metadata": {
        "id": "pXu0tSIbNn7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.norm1 = norm(inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.norm2 = norm(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "\n",
        "        out = self.relu(self.norm1(x))\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(out)\n",
        "\n",
        "        out = self.conv1(out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        return out + shortcut"
      ],
      "metadata": {
        "id": "E1Rb_TPbtsaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConcatConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True, transpose=False):\n",
        "        super(ConcatConv2d, self).__init__()\n",
        "        module = nn.ConvTranspose2d if transpose else nn.Conv2d\n",
        "        self._layer = module(\n",
        "            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        tt = torch.ones_like(x[:, :1, :, :]) * t\n",
        "        ttx = torch.cat([tt, x], 1)\n",
        "        return self._layer(ttx)"
      ],
      "metadata": {
        "id": "3B-pkbvVu2Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ODEfunc(nn.Module):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(ODEfunc, self).__init__()\n",
        "        self.norm1 = norm(dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
        "        self.norm2 = norm(dim)\n",
        "        self.conv2 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
        "        self.norm3 = norm(dim)\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        out = self.norm1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(t, out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(t, out)\n",
        "        out = self.norm3(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "kH3JBRZsu7nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ODEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, odefunc):\n",
        "        super(ODEBlock, self).__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.integration_time = torch.tensor([0, 1]).float()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol, method='euler')\n",
        "        return out[1]\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.odefunc.nfe\n",
        "\n",
        "    @nfe.setter\n",
        "    def nfe(self, value):\n",
        "        self.odefunc.nfe = value"
      ],
      "metadata": {
        "id": "h3N4-W9Wu-fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
        "        return x.view(-1, shape)"
      ],
      "metadata": {
        "id": "DMSf2dYVvDo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunningAverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.avg = val\n",
        "        else:\n",
        "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
        "        self.val = val"
      ],
      "metadata": {
        "id": "BsGiJOJfvF3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist_loaders(data_aug=False, batch_size=128, test_batch_size=1000, perc=1.0):\n",
        "    if data_aug:\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(28, padding=4),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "    else:\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_train), batch_size=batch_size,\n",
        "        shuffle=True, num_workers=2, drop_last=True\n",
        "    )\n",
        "\n",
        "    train_eval_loader = DataLoader(\n",
        "        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_test),\n",
        "        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        datasets.MNIST(root='.data/mnist', train=False, download=True, transform=transform_test),\n",
        "        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader, train_eval_loader\n"
      ],
      "metadata": {
        "id": "cgAWZuNWvGfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inf_generator(iterable):\n",
        "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
        "        for i, (x, y) in enumerate(inf_generator(train_loader)):\n",
        "    \"\"\"\n",
        "    iterator = iterable.__iter__()\n",
        "    while True:\n",
        "        try:\n",
        "            yield iterator.__next__()\n",
        "        except StopIteration:\n",
        "            iterator = iterable.__iter__()"
      ],
      "metadata": {
        "id": "s9MUOMgNvJXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):\n",
        "    initial_learning_rate = args.lr * batch_size / batch_denom\n",
        "\n",
        "    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\n",
        "    vals = [initial_learning_rate * decay for decay in decay_rates]\n",
        "\n",
        "    def learning_rate_fn(itr):\n",
        "        lt = [itr < b for b in boundaries] + [True]\n",
        "        i = np.argmax(lt)\n",
        "        return vals[i]\n",
        "\n",
        "    return learning_rate_fn"
      ],
      "metadata": {
        "id": "tR2S_ISFvMcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(x, K):\n",
        "    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)"
      ],
      "metadata": {
        "id": "3VvJeYCqvOvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, dataset_loader):\n",
        "    total_correct = 0\n",
        "    for x, y in dataset_loader:\n",
        "        x = x.to(device)\n",
        "        y = one_hot(np.array(y.numpy()), 10)\n",
        "\n",
        "        target_class = np.argmax(y, axis=1)\n",
        "        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)\n",
        "        total_correct += np.sum(predicted_class == target_class)\n",
        "    return total_correct / len(dataset_loader.dataset)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def makedirs(dirname):\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)"
      ],
      "metadata": {
        "id": "zPjkdOBnvQzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):\n",
        "    logger = logging.getLogger()\n",
        "    if debug:\n",
        "        level = logging.DEBUG\n",
        "    else:\n",
        "        level = logging.INFO\n",
        "    logger.setLevel(level)\n",
        "    if saving:\n",
        "        info_file_handler = logging.FileHandler(logpath, mode=\"a\")\n",
        "        info_file_handler.setLevel(level)\n",
        "        logger.addHandler(info_file_handler)\n",
        "    if displaying:\n",
        "        console_handler = logging.StreamHandler()\n",
        "        console_handler.setLevel(level)\n",
        "        logger.addHandler(console_handler)\n",
        "    # logger.info(filepath)\n",
        "    # with open(filepath, \"r\") as f:\n",
        "    #     logger.info(f.read())\n",
        "\n",
        "    # for f in package_files:\n",
        "    #     logger.info(f)\n",
        "    #     with open(f, \"r\") as package_f:\n",
        "    #         logger.info(package_f.read())\n",
        "\n",
        "    return logger\n"
      ],
      "metadata": {
        "id": "Iacb8joZvUG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main function for running\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    makedirs(args.save)\n",
        "    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath('')) # mod to adjust for ipynb\n",
        "    logger.info(args)\n",
        "\n",
        "    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # initialise data storage for plotting\n",
        "    epochs = []\n",
        "    train_accs = []\n",
        "    test_accs = []\n",
        "    epoch_times = []\n",
        "\n",
        "    is_odenet = args.network == 'odenet'\n",
        "\n",
        "    if args.downsampling_method == 'conv':\n",
        "        downsampling_layers = [\n",
        "            nn.Conv2d(1, 64, 3, 1),\n",
        "            norm(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 4, 2, 1),\n",
        "            norm(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 4, 2, 1),\n",
        "        ]\n",
        "    elif args.downsampling_method == 'res':\n",
        "        downsampling_layers = [\n",
        "            nn.Conv2d(1, 64, 3, 1),\n",
        "            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
        "            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
        "        ]\n",
        "\n",
        "    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]\n",
        "    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]\n",
        "\n",
        "    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\n",
        "\n",
        "    logger.info(model)\n",
        "    logger.info('Number of parameters: {}'.format(count_parameters(model)))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    train_loader, test_loader, train_eval_loader = get_mnist_loaders(\n",
        "        args.data_aug, args.batch_size, args.test_batch_size\n",
        "    )\n",
        "\n",
        "    data_gen = inf_generator(train_loader)\n",
        "    batches_per_epoch = len(train_loader)\n",
        "\n",
        "    lr_fn = learning_rate_with_decay(\n",
        "        args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\n",
        "        decay_rates=[1, 0.1, 0.01, 0.001]\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
        "\n",
        "    best_acc = 0\n",
        "    batch_time_meter = RunningAverageMeter()\n",
        "    f_nfe_meter = RunningAverageMeter()\n",
        "    b_nfe_meter = RunningAverageMeter()\n",
        "    end = time.time()\n",
        "\n",
        "    for epoch in range(args.nepochs):\n",
        "        start_epoch_time = time.time()\n",
        "\n",
        "        for itr in range(batches_per_epoch):\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_fn(itr)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            x, y = data_gen.__next__()\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            if is_odenet:\n",
        "                nfe_forward = feature_layers[0].nfe\n",
        "                feature_layers[0].nfe = 0\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if is_odenet:\n",
        "                nfe_backward = feature_layers[0].nfe\n",
        "                feature_layers[0].nfe = 0\n",
        "\n",
        "            batch_time_meter.update(time.time() - end)\n",
        "            if is_odenet:\n",
        "                f_nfe_meter.update(nfe_forward)\n",
        "                b_nfe_meter.update(nfe_backward)\n",
        "            end = time.time()\n",
        "\n",
        "        epoch_duration = time.time() - start_epoch_time\n",
        "        epoch_times.append(epoch_duration)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            train_acc = accuracy(model, train_eval_loader)\n",
        "            val_acc = accuracy(model, test_loader)\n",
        "            if val_acc > best_acc:\n",
        "                torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))\n",
        "                best_acc = val_acc\n",
        "\n",
        "        epochs.append(epoch)\n",
        "        train_accs.append(train_acc)\n",
        "        test_accs.append(val_acc)\n",
        "\n",
        "        logger.info(\n",
        "            f\"Epoch {epoch:04d} | Time {epoch_duration:.3f} | Train Acc {train_acc:.4f} | Test Acc {val_acc:.4f} | NFE-F {f_nfe_meter.avg:.1f} | NFE-B {b_nfe_meter.avg:.1f}\"\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "DiAmwzZ7vW2P",
        "outputId": "68ab987e-009c-4233-9692-c9368b6f4a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'makedirs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e05754b6bf5e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mod to adjust for ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'makedirs' is not defined"
          ]
        }
      ]
    }
  ]
}